<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>statistics on Golden Hat</title>
    <link>https://frankccccc.github.io/blog/categories/statistics/</link>
    <description>Recent content in statistics on Golden Hat</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Feb 2021 12:39:16 +0800</lastBuildDate><atom:link href="https://frankccccc.github.io/blog/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A Guide Of Variational Lower Bound</title>
      <link>https://frankccccc.github.io/blog/posts/a_guide_of_variational_lower_bound/</link>
      <pubDate>Tue, 23 Feb 2021 12:39:16 +0800</pubDate>
      
      <guid>https://frankccccc.github.io/blog/posts/a_guide_of_variational_lower_bound/</guid>
      <description>Problem Setup It is also knowd as Evidence Lower Bound(ELBO) or VLB. We can assume that $X$ are observations (data) and $Z$ are hidden/latent variables. In general, we can also imagine $Z$ as a parameter and the relationship between $Z$ and $X$ are represented as the following
In the mean time, by the definition of Bayes&#39; Theorem and conditional probability, we can get
$$p(Z | X) = \frac{p(X | Z) p(Z)}{p(X)} = \frac{p(X | Z) p(Z)}{\int_{Z} p(X, Z)}$$</description>
    </item>
    
    <item>
      <title>Some Intuition Of MLE, MAP, and Bayesian Estimation</title>
      <link>https://frankccccc.github.io/blog/posts/some_intuition_of_mle_map_and_bayesian_estimation/</link>
      <pubDate>Fri, 19 Feb 2021 11:15:15 +0800</pubDate>
      
      <guid>https://frankccccc.github.io/blog/posts/some_intuition_of_mle_map_and_bayesian_estimation/</guid>
      <description>The main different between 3 kinds of estimation is What do we assume for the prior? The Maximum Likelihood Estimation(MLE) doesn&amp;rsquo;t use any prior but only maiximize the probability according to the samples. On the other hand, MAP and Bayesian both use priors to estimate the probability. The Maximum A Posteriori(MAP) only use the probability of single event while Bayesian Estimation see a distribution as the prior.
To be continue&amp;hellip;</description>
    </item>
    
  </channel>
</rss>
