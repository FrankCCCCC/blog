<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>A Very Brief Introduction to Gaussian Process and Bayesian Optimization | Golden Hat</title><meta name=keywords content="Gaussian process,Gaussian,gp,Bayesian optimization,machine learning,ml,numerical optimization"><meta name=description content="An introduction of Gaussian Process and Bayesian Optimization"><meta name=author content="SY Chou"><link rel=canonical href=https://frankccccc.github.io/blog/posts/intro_gp_bayes_opt/><script async src="https://www.googletagmanager.com/gtag/js?id=G-S9MCZ2NDS7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-S9MCZ2NDS7')</script><link href=/blog/assets/css/stylesheet.min.3768d020b7a9fd49f21ddb7d521ce9b187ce47c2929b883041396159d4d25553.css integrity="sha256-N2jQILep/UnyHdt9UhzpsYfOR8KSm4gwQTlhWdTSVVM=" rel="preload stylesheet" as=style><link rel=icon href=https://frankccccc.github.io/blog/img/just_imgs/gold_empty_circle.svg><link rel=icon type=image/png sizes=16x16 href=https://frankccccc.github.io/blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://frankccccc.github.io/blog/favicon-32x32.png><link rel=apple-touch-icon href=https://frankccccc.github.io/blog/apple-touch-icon.png><link rel=mask-icon href=https://frankccccc.github.io/blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.85.0"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css integrity=sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js integrity=sha384-YNHdsYkH6gMx9y3mRkmcJ2mFUjTd0qNQQvY9VYZgQd7DcN7env35GzlmFaZ23JGp crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:!0},{left:'$',right:'$',display:!1},{left:'\\(',right:'\\)',display:!1},{left:'\\[',right:'\\]',display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-S9MCZ2NDS7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-S9MCZ2NDS7')</script><meta property="og:title" content="A Very Brief Introduction to Gaussian Process and Bayesian Optimization"><meta property="og:description" content="An introduction of Gaussian Process and Bayesian Optimization"><meta property="og:type" content="article"><meta property="og:url" content="https://frankccccc.github.io/blog/posts/intro_gp_bayes_opt/"><meta property="og:image" content="https://frankccccc.github.io/blog/img/just_imgs/ny_skyline.jpg"><meta property="article:published_time" content="2021-02-16T17:28:58+08:00"><meta property="article:modified_time" content="2021-02-16T17:28:58+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://frankccccc.github.io/blog/img/just_imgs/ny_skyline.jpg"><meta name=twitter:title content="A Very Brief Introduction to Gaussian Process and Bayesian Optimization"><meta name=twitter:description content="An introduction of Gaussian Process and Bayesian Optimization"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://frankccccc.github.io/blog/posts/"},{"@type":"ListItem","position":2,"name":"A Very Brief Introduction to Gaussian Process and Bayesian Optimization","item":"https://frankccccc.github.io/blog/posts/intro_gp_bayes_opt/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"A Very Brief Introduction to Gaussian Process and Bayesian Optimization","name":"A Very Brief Introduction to Gaussian Process and Bayesian Optimization","description":"Gaussian Process Big Picture and Background Intuitively, Gaussian distribution define the state space, while Gaussian Process define the function space\nBefore we introduce Gaussian ‚Ä¶","keywords":["Gaussian process","Gaussian","gp","Bayesian optimization","machine learning","ml","numerical optimization"],"articleBody":"Gaussian Process Big Picture and Background Intuitively, Gaussian distribution define the state space, while Gaussian Process define the function space\nBefore we introduce Gaussian process, we should understand Gaussian distriution at first. For a RV(random variable) $X$ that follow Gaussian Distribution $\\mathcal{N}(0, 1)$ should be following image:\nThe P.D.F should be\n$$x \\sim \\mathcal{N}(\\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{- \\frac{1}{2} (\\frac{- \\mu}{\\sigma})^2}$$\nAs for Multivariate Gaussian Distribution, given 2 RV $x$, $y$ both 2 RV follow Gaussian Distribution $\\mathcal{N}(0, 1)$ we can illustrate it as\nThe P.D.F should be\nFor a set of random variables $X = (x_1, ‚Ä¶, x_k)$ that follow Gaussian distribution\n$$(x_1, ‚Ä¶, x_k) \\sim \\mathcal{N}(\\mu, \\Sigma) = \\frac{1}{\\sqrt{(2 \\pi)^k |\\Sigma|}} e^{- \\frac{1}{2} (X- \\mu)^{\\top} \\Sigma^{-1} (X- \\mu)}$$\nwhere $\\mu$ is the mean and $\\Sigma$ is the covariance matrix.\nThe Gaussian process can be regarded as a function space, for example, given a function $f(x)$ The Gaussian process can be illustrated as following:\nThe blue solid line represent the mean of the Gaussian process and the shaded blue area represent the standard deviation(which means the uncertainty of the RV) for the corresponding RV. For example, while $x=-4$, the function $f(4) = \\mathcal{N}(0, 2)$. That means the Gaussian process gives a Gaussian distribution $\\mathcal{N}(0, 2)$ to describe the possible value of $f(-4)$. The most likely value of $f(-4)$ is 0 (which is the mean of the distribution). As the figure shows, the Gaussian process is quite simple that the mean function is a constant 0 and the standard deviation is 2.\nThe dotted line are the functions sampled from the Gaussian process. Each line gives a mapping function from $x$ to $f(x)$.\nNote that the explaination above is from the point of view of function approximation. From the perspective of random process, the Gaussian process can be regarded as a time-variant system that the distribution is changing along the time.\nAfter understanding the priori, we can see the posteriori of Gaussian Process.\nIn the above figure, we estimate 5 points and re-draw the plot. The uncertainty of the estimated points become very small since we now have actual values of them via estimations.\nIn the view of 3D of the same posteriori, the Z axis means the probability. It illustrates the Gaussian process as a series of varying Gaussian distributions along the different values of $x$.\nThe above figure can be generated by this notebook. Specically thanks Martin Krasser. My notebook code is based on it.\nDefinition A Gaussian process is a time continuous stochastic process ${x_t; t \\in T}$ is Gaussian if and only if for every finite set of indices $t_1, ‚Ä¶, t_k$ in the index set $T$, $x_{t1},‚Ä¶x_{tk} = (x_{t1}, ‚Ä¶, x_{tk})$ is a multivariate Gaussian random variable.\nFor example, any point $x_1, ‚Ä¶ x_N \\in X, X \\in \\mathbb{R}^d$(Real Number with dimension $d$) is assigned a random variable $f(x)$ and where the joint distribution of a finite number of these variables $p(f(x_1),‚Ä¶,f(x_N))$ is itself Gaussian:\n$$p(f|X) = \\mathcal{N}(f|\\mu, K)$$\nwhere $\\mu$ is a vector which consists of mean function and $K$ is a covariance matrix which consists of covariance function or kernel function $\\kappa$. The set of mean function $\\mu = (m(x_1),‚Ä¶,m(x_N))$ give the mean value over set $X$. The set of kernel function is $K={K_{ij} = \\kappa(x_i,x_j)) where x_i, x_j \\in X}$ which define the correlaton between 2 values $x_i$ and $x_j$.\nNote that a data point $x_i$ or $x_j$ might be multi-dimensions. The kernel functions may defined on the vectors as well.\nKernel To understand the kernel function intuitively, the kernel function can be regarded as a kind of distance metric which give the distance in another space. For example, the kernel $k(x_i, x_j) = {x_i}^2 + {x_j}^2$ map the Cartesian coordinate to polar coordinate and convert the Euclidean distance into radius.\nSome common kernels are:\n  Constant Kernel:\n$K_C(x_i, x_j) = C$\n  RBF Kernel:\n$K_{RBF}(x_i, x_j) = e^{-\\frac{|| x_i - x_j ||^2}{2 \\sigma^2}}$\n  Periodic Kernel\nSuitable for periodic relation\n$K_{P}(x_i, x_j) = e^{-\\frac{2 \\sin^2 (\\frac{d}{2})}{\\ell^2}}$\n  Polynomial Kernel\n$K_{Poly}(x_i, x_j) = ( x_i^{\\top}x_j+ c)^d$\n  Neural Network Kernel\nModel the neural network as GP, aka neural network Gaussian Process(NNGP). Intuitively, the kernel of NNGP compute the distance between the output vectors of 2 input data points.\nWe define the following functions as neural networks with fully-conntected layers:\n$$z_{i}^{1}(x) = b_i^{1} + \\sum_{j=1}^{N_1} \\ W_{ij}^{1}x_j^1(x), \\ \\ x_{j}^{1}(x) = \\phi(b_i^{0} + \\sum_{k=1}^{d_{in}} \\ W_{ik}^{0}x_k(x))$$\nwhere $b_i^{1}$ is the $i$th-bias of the second layer(the same as first hidden layer), $W_{ij}^{1}$ is the $i$th-weights of the first layer(the same as input layer) , function $\\phi$ is the activation function, and $x$ is the input data of the neural network. As a result,\nThus, the kernel of $l$-th layer is\n$$K_{NN}^l(x, x') = \\sigma_b^2 + \\sigma_w^2 E_{z_i^{l-1} \\sim GP(0, K^{l-1})}[\\phi(z_i^{l-1}(x)) \\phi(z_i^{l-1}(x'))]$$\nFor more detail, please refer to this slide and the paper Deep Neural Networks as Gaussian Processes.\n  For more detail, please refer to A Visual Exploration of Gaussian Processes. You can play with interactive widgets on the website.\nInference Given a training dataset with noise-free function values $f$ at inputs $X$, a GP prior can be converted into a GP posterior $p(f^{\\ast}|X^{\\ast},X,f)$ which can then be used to make predictions $f^{\\ast}$ at new inputs $X^{\\ast}$ By definition of a GP, the joint distribution of observed values $f$ and predictions $f^{\\ast}$ is again a Gaussian which can be partitioned into\n$$ \\begin{pmatrix} f\\newline f^{\\ast} \\end{pmatrix} \\sim \\mathcal{N} \\begin{pmatrix} 0, \\begin{pmatrix} K \u0026 K^{\\ast}\\newline K^{\\ast \\top} \u0026 K^{\\ast \\ast} \\end{pmatrix} \\end{pmatrix}$$\nwhere $K^{\\ast} = \\kappa(X,X^{\\ast})$ and $K^{\\ast \\ast} = \\kappa(X^{\\ast},X^{\\ast})$. With $N$ training data and $N^{\\ast}$ new input data $K$ is a $N√óN$ matrix , $K^{\\ast}$ a $N√óN^{\\ast}$ matrix and $K^{\\ast \\ast}$ a $N^{\\ast}√óN^{\\ast}$ matrix.\nWe‚Äôve known conditional distribution rules.\nAs a result, the predictive Gaussian Distribution is\n$$p(f^{\\ast} | X^{\\ast},X,f) = \\mathcal{N}(f^{\\ast} | \\mu^{\\ast}, \\Sigma^{\\ast})$$\n$$\\mu^{\\ast} = K^{\\ast \\top} K^{-1} f$$\n$$\\Sigma^{\\ast} = K^{\\ast \\ast} - K^{\\ast \\top} K^{-1} K^{\\ast}$$\nHowever, the above equations don‚Äôt consider the effect of noise. Suppose we need to evalutate a noisy model $y=f+\\epsilon$ where $\\epsilon \\sim \\mathcal{N}(0, \\sigma_y^2 I)$ is the noise. The noise follows normal distribution and has a covariance matrix $\\sigma_y^2 I$. Thus, the predictive distribution is\n$$p(f^{\\ast} | X^{\\ast},X,y) = \\mathcal{N}(f^{\\ast} | \\mu^{\\ast}, \\Sigma^{\\ast})$$\n$$\\mu^{\\ast} = K^{\\ast \\top} K_{y}^{-1} y$$\n$$\\Sigma^{\\ast} = K^{\\ast \\ast} - K^{\\ast \\top} K_{y}^{-1} K^{\\ast}$$\nwhere $K_{y}^{-1} = K + \\sigma_y^2 I$(linearilty of Gaussian distribution). Finally, we also want to replace the noise-free prediction $f^{\\ast}$ with noisy prediction $y^{\\ast}$. We can derive\n$$p(y^{\\ast} | X^{\\ast},X,y) = \\mathcal{N}(y^{\\ast} | \\mu^{\\ast}, \\Sigma^{\\ast} + \\sigma_y^2 I)$$\nFinally, we get the probability of noisy prediction $y^{\\ast}$ which conditions on noisy training dataset $X,y$ and test dataset $X^{\\ast}$.\n Bayesian Optimization In many machine learning or optimization problem, we need to optimize an unkown object function $f$. One of the solutions to optimize function $f$ is Bayesian Optimization. Bayesian Optimization assume the object function $f$ follows a distribution or prior model. This prior model is called surrogate model. We sample from the object function $f$ and approximate the function $f$ with surrogate model. The extra information like uncertainty provided from surrogate model contribute to the sample-efficiency of Bayesian optimization. In the mean time, we also use the acquisition function to choose the next sampling point.\nDefinition Formaly, suppose we have a block-box function $f : X \\to R$ that we with to minimize on some domain $x \\subseteq X$ . That is, the Bayesian optimization wish to \u001bfind\n$$\\begin{equation} x^{\\ast} = \\mathop{\\arg\\min}_{x \\in X} \\ \\ f(x) \\end{equation}$$\nIf we use Gaussian Process as prior(Surrogate Model), we can get\n$$p(f) = GP(f; \\mu, K)$$\nGiven observations $D = (x,f)$, we can condition our distribution on $D$ as usual\n$$p(f | D) = GP(f; \\mu_{f|D}, K_{f|D})$$\nSurrogate Model A popular model is Gaussian Process. Gaussian process defines a prior over functions and provides a flexiable, powerful and, smooth model which is especially suitable for dynamic models.\nAlgorithm The Bayesian optimization procedure is as follows.\n For index $t=1,2,‚Ä¶$ and an acquisition function $a(x|D)$\nrepeat:\n Find the next sampling point $x_t$ by optimizing the acquisition function over the surrogate model: $x_t = \\mathop{\\arg\\max}_{x \\in X} \\ a(x|D_{1:t‚àí1})$ Or\n$x_t = \\mathop{\\arg\\min}_{x \\in X} \\ a(x|D_{1:t‚àí1})$ Depends on the definition of acquisition function $a(x|D_{1:t‚àí1})$\n Obtain a possibly noisy sample $y_t=f(x_t)+\\epsilon_t$ from the objective function $f$. Add the sample to previous samples $D_{1:t}=D_{1:t‚àí1},(x_t,y_t)$ and update the surrogate model.   Probability improvement(PI) Method A naive idea is always evaluating the points with lowest value and then we can obtain a better result in every iteration. The PI method do the same thing exactly. However, the Gaussian Process gives a distribution of $f(x)$ on point $x$. As a result, in practice, we give an threshold $f'$, integrate the probability of $x PI always choose the point having largest probability of $x .\nFormaly, we can define an utility function $u(x)$\n$$u(x) = \\begin{cases} 0, \\ \\ f(x)  f'\\newline 1, \\ \\ f(x) \\leq f' \\end{cases}$$\nThen, integrate the probability of $f(x) \\leq f'$\n$$ a_{PI}(x|D) = E[u(x) | x, D] = \\int_{-\\infty}^{f'} \\mathcal{N}(f; \\mu(x), \\kappa(x, x)) \\ df =\\phi(f'; \\mu(x), \\kappa(x, x)) $$\nFinally, we choose next evaluating point $x_t$ with highest probability $a_{PI}(x|D_{1:t‚àí1})$\n$\\begin{equation} x_t = \\mathop{\\arg\\max}_{x \\in X} \\ \\ a_{PI}(x|D_{1:t‚àí1}) \\end{equation}$ Expected improvement(EI) Method PI algorithm is easy to understand. However, PI might get stuck in local optimal and underexplore globally. A better way is that we evaluates $f$ at the point that, in expectation, improves upon $f'$ the most. That is the idea of EI algorithm.\nFormaly, we suppose that $f'$ is the minimal value of $f$ observed so far. We can define an utility function as following:\n$$u(x) = \\mathop{\\max} (0, f' ‚àí f(x))$$\nThe ultility function can be regarded as the advanrage $f' - f(x)$ versus the current optimal $f'$. Then, we can derive the expectation via integration\n$$ a_{EI}(x|D) = E[u(x) | x, D] = \\int_{-\\infty}^{f'} (f' - f) \\mathcal{N}(f; \\mu(x), \\kappa(x, x)) \\ df $$\n$$ =(f' - \\mu(x))\\phi(f'; \\mu(x), \\kappa(x, x)) + \\kappa(x, x) \\mathcal{N}(f'; \\mu(x), \\kappa(x, x)) $$\nWe always choose the next evaluating point $x_t$ which has highest $a_{EI}(x|D_{1:t‚àí1})$, thus\n$\\begin{equation} x_t = \\mathop{\\arg\\max}_{x \\in X} \\ \\ a_{EI}(x|D_{1:t‚àí1}) \\end{equation}$ Intuitively, the term $(f' - \\mu(x))\\phi(f'; \\mu(x), \\kappa(x, x))$ can be seen as exploitation(it encourage to evaluate the point with higher advantage, lower $\\mu(x)$), since it means how much advantage does point $x$ has. The term $\\kappa(x, x) \\mathcal{N}(f'; \\mu(x), \\kappa(x, x))$ represents how much uncertainty does point $x$ has, so it can be viewed as exploration(it encourage to evaluate the point with higher uncertainty, higher $\\kappa(x, x)$). EI algorithm can trade off the exploration and exploitation automatically and also the most popular algorithm of Bayesian Optimization.\nBayesian Upper Confident Bound(Bayesian UCB, aka GP-UCB) Method Before diving to Bayesian UCB method, please understand the multi-armed bandit problem and UCB first.\nBayesian UCB inherents UCB. They both give a relation between upper bound and probability confidence. The different thing is UCB finds the relation with Hoeffding‚Äôs Inequality while Bayesian UCB find the relation with Gaussian distribution itself.\nFor example, it is common that we know if we sample values from Gaussian distribution, 95% of them are between the mean plus 2 standard deviation and mean subtract 2 standard deviation.\nFormally, we define the acquisition function as following\n$$ a_{UCB}(x|D; \\beta) = \\mu(x) - \\beta \\sigma(x) $$\nwhere $\\beta  0$ is a tradeo\u001dff parameter and $\\sigma(x) = \\sqrt{\\kappa(x, x)}$ is the marginal standard deviation of $f(x)$.\nAccording the acquisition function, we always choose the next best evaluating point $x_t$\n$\\begin{equation} x_t = \\mathop{\\arg\\min}_{x \\in X} \\ \\ a_{UCB}(x|D_{1:t‚àí1}; \\beta) \\end{equation}$ Again, the GP-UCB acquisition function contains explicit exploitation ($\\mu(x)$) and exploration ($\\sigma(x)$) terms. Nonetheless, strong theoretical results are known for GP-UCB, namely, that under certain conditions, the iterative application of this acquisition function will converge to the true global minimum of $f$.\nEntropy Search Since we‚Äôve known the goal of the optimization problem is\n$$\\begin{equation} x^{\\ast} = \\mathop{\\arg\\min}_{x \\in X} \\ \\ f(x) \\end{equation}$$\nwhere $x^{\\ast}$ is the global optimal over the black-box function $f$. The entropy search aims to minimizing the entropy of $p(x^{\\ast} | D)$. That is, minimize the uncerntainty of $x^{\\ast}$ over the known data set $D$. We can define an utility function as following\n$$u(x) = H[x^{\\ast} | D] - H[x^{\\ast} | D, x, f(x)]$$\nwhere $H$ represent the Shannon entropy of the corresponding data point. The $u(x)$ means how much uncertinty of $p(x^{\\ast} | D)$ does the evaluation reduce after the data point $x$ is evaluated. In most of the time, the entropy(uncertainty) of $p(x^{\\ast} | D)$ should decrease after we evaluate more data points, so $u(x)$ should be positive in general. Thus, the acquisition function should be\n$$a_{ES}(x|D) = E[u(x) | x, D]$$\nHowever, we know $u(x)$ cannot be computed directly since it doesn‚Äôt have close form. There are a series of approximations trying to do it but I will ignore thme in this blog. Finally, we can choose the next evaluation point $x_t$ as following\n$\\begin{equation} x_t = \\mathop{\\arg\\max}_{x \\in X} \\ \\ a_{ES}(x|D_{1:t‚àí1}; \\beta) \\end{equation}$ Reference This article is mainly based on\nGaussian Process\n  Gaussian processes by Martin Krasser\nProvide Python code to inference data with GP.\n  (ML 19.1) Gaussian processes - definition and first examples\nMade by mathematicalmonk. Give an intuitive explaination of Gaussian processes.\n  A Visual Exploration of Gaussian Processes\nProvide a lot of interactive widgets to play around with Gausssian Process but fewer math.\n  Gaussian Processes - Part 1\nAnother video providing a detailed explaination of Gaussian Process.\n  ML Tutorial: Gaussian Processes (Richard Turner)\nAnother video providing a detailed explaination of Gaussian Process.\n  UBC CS - Machine learning - Introduction to Gaussian processes\nUBC CS - Machine learning - Gaussian processes\nAnother video providing a detailed explaination of Gaussian Process.\n  Conditional Gaussian Distribution\n (PP 6.9) Conditional distributions of a Gaussian StackExchange - Deriving the conditional distributions of a multivariate normal distribution  Bayesian Optimization\n Bayesian optimization by Martin Krasser UAI 2018 2. Bayesian Optimization Washington University CSE515 - Bayesian Optimization  Kalman Filter\n  Bzarg: How a Kalman filter works, in pictures\nIntuitively explain Kalman Filter with picture \u0026 examples.\n  ÂõæËØ¥Âç°Â∞îÊõºÊª§Ê≥¢Ôºå‰∏Ä‰ªΩÈÄö‰øóÊòìÊáÇÁöÑÊïôÁ®ã\nIntuitively explain Kalman Filter with picture \u0026 examples. The article is translated from Bzarg: How a Kalman filter works.\n  ","wordCount":"2383","inLanguage":"en","image":"https://frankccccc.github.io/blog/img/just_imgs/ny_skyline.jpg","datePublished":"2021-02-16T17:28:58+08:00","dateModified":"2021-02-16T17:28:58+08:00","author":{"@type":"Person","name":"SY Chou"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://frankccccc.github.io/blog/posts/intro_gp_bayes_opt/"},"publisher":{"@type":"Organization","name":"Golden Hat","logo":{"@type":"ImageObject","url":"https://frankccccc.github.io/blog/img/just_imgs/gold_empty_circle.svg"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://frankccccc.github.io/blog/ accesskey=h title="Golden Hat (Alt + H)"><img src=/blog/img/just_imgs/gold_empty_circle.svg alt=logo aria-label=logo height=35>Golden Hat</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu onscroll=menu_on_scroll()><li><a href=https://frankccccc.github.io/blog/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://frankccccc.github.io/blog/series title=Series><span>Series</span></a></li><li><a href=https://frankccccc.github.io/blog/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://frankccccc.github.io/blog/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://frankccccc.github.io/blog/>Home</a>&nbsp;¬ª&nbsp;<a href=https://frankccccc.github.io/blog/posts/>Posts</a></div><h1 class=post-title>A Very Brief Introduction to Gaussian Process and Bayesian Optimization</h1><div class=post-description>An introduction of Gaussian Process and Bayesian Optimization</div><div class=post-meta>February 16, 2021&nbsp;¬∑&nbsp;12 min&nbsp;¬∑&nbsp;SY Chou</div></header><figure class=entry-cover><img src=https://frankccccc.github.io/blog/img/just_imgs/ny_skyline.jpg alt></figure><div class=post-content><h1 id=gaussian-process>Gaussian Process<a hidden class=anchor aria-hidden=true href=#gaussian-process>#</a></h1><h2 id=big-picture-and-background>Big Picture and Background<a hidden class=anchor aria-hidden=true href=#big-picture-and-background>#</a></h2><p>Intuitively, Gaussian distribution define the <strong>state space</strong>, while Gaussian Process define the <strong>function space</strong></p><p>Before we introduce Gaussian process, we should understand Gaussian distriution at first. For a RV(random variable) $X$ that follow Gaussian Distribution $\mathcal{N}(0, 1)$ should be following image:</p><p><img src=/blog/img/gp/normal01.png alt></p><p>The P.D.F should be</p><p>$$x \sim \mathcal{N}(\mu, \sigma) = \frac{1}{\sigma \sqrt{2 \pi}} e^{- \frac{1}{2} (\frac{- \mu}{\sigma})^2}$$</p><p>As for Multivariate Gaussian Distribution, given 2 RV $x$, $y$ both 2 RV follow Gaussian Distribution $\mathcal{N}(0, 1)$ we can illustrate it as</p><p><img src=/blog/img/gp/multivariate_gaussian.png alt></p><p>The P.D.F should be</p><p>For a set of random variables $X = (x_1, &mldr;, x_k)$ that follow Gaussian distribution</p><p>$$(x_1, &mldr;, x_k) \sim \mathcal{N}(\mu, \Sigma) = \frac{1}{\sqrt{(2 \pi)^k |\Sigma|}} e^{- \frac{1}{2} (X- \mu)^{\top} \Sigma^{-1} (X- \mu)}$$</p><p>where $\mu$ is the mean and $\Sigma$ is the covariance matrix.</p><p>The Gaussian process can be regarded as a <strong>function space</strong>, for example, given a function $f(x)$ The Gaussian process can be illustrated as following:</p><p><img src=/blog/img/gp/gp.png alt></p><p>The blue solid line represent the mean of the Gaussian process and the shaded blue area represent the standard deviation(which means the uncertainty of the RV) for the corresponding RV. For example, while $x=-4$, the function $f(4) = \mathcal{N}(0, 2)$. That means the Gaussian process gives a Gaussian distribution $\mathcal{N}(0, 2)$ to describe the possible value of $f(-4)$. The most likely value of $f(-4)$ is 0 (which is the mean of the distribution). As the figure shows, the Gaussian process is quite simple that the mean function is a constant 0 and the standard deviation is 2.</p><p>The dotted line are the functions sampled from the Gaussian process. Each line gives a mapping function from $x$ to $f(x)$.</p><p>Note that the explaination above is from the point of view of function approximation. <strong>From the perspective of random process, the Gaussian process can be regarded as a time-variant system that the distribution is changing along the time.</strong></p><p>After understanding the priori, we can see the posteriori of Gaussian Process.</p><p><img src=/blog/img/gp/gp_posterior.png alt></p><p>In the above figure, we estimate 5 points and re-draw the plot. The uncertainty of the estimated points become very small since we now have actual values of them via estimations.</p><p><img src=/blog/img/gp/gp_3d.png alt></p><p>In the view of 3D of the same posteriori, the Z axis means the probability. It illustrates the Gaussian process as a series of varying Gaussian distributions along the different values of $x$.</p><p>The above figure can be generated by <a href="https://colab.research.google.com/drive/1hsQu8pok1d9VfZDQqjsgiLiqwXhWvrQw?usp=sharing">this notebook</a>. Specically thanks <a href=http://krasserm.github.io/2018/03/19/gaussian-processes/>Martin Krasser</a>. My notebook code is based on it.</p><h2 id=definition>Definition<a hidden class=anchor aria-hidden=true href=#definition>#</a></h2><p>A Gaussian process is a time continuous stochastic process ${x_t; t \in T}$ is Gaussian if and only if for every finite set of indices $t_1, &mldr;, t_k$ in the index set $T$, $x_{t1},&mldr;x_{tk} = (x_{t1}, &mldr;, x_{tk})$ is a multivariate Gaussian random variable.</p><p>For example, any point $x_1, &mldr; x_N \in X, X \in \mathbb{R}^d$(Real Number with dimension $d$) is assigned a random variable $f(x)$ and where the joint distribution of a finite number of these variables $p(f(x_1),‚Ä¶,f(x_N))$ is itself Gaussian:</p><p>$$p(f|X) = \mathcal{N}(f|\mu, K)$$</p><p>where $\mu$ is a vector which consists of <strong>mean function</strong> and $K$ is a covariance matrix which consists of <strong>covariance function</strong> or <strong>kernel function $\kappa$</strong>. The set of mean function $\mu = (m(x_1),‚Ä¶,m(x_N))$ give the mean value over set $X$. The set of kernel function is $K={K_{ij} = \kappa(x_i,x_j)) where x_i, x_j \in X}$ which define the correlaton between 2 values $x_i$ and $x_j$.</p><p>Note that a data point $x_i$ or $x_j$ might be multi-dimensions. <strong>The kernel functions may defined on the vectors as well.</strong></p><h2 id=kernel>Kernel<a hidden class=anchor aria-hidden=true href=#kernel>#</a></h2><p>To understand the kernel function intuitively, the kernel function can be regarded as a kind of <strong>distance metric</strong> which give the distance in another space. For example, the kernel $k(x_i, x_j) = {x_i}^2 + {x_j}^2$ map the Cartesian coordinate to polar coordinate and convert the Euclidean distance into radius.</p><p>Some common kernels are:</p><ul><li><p>Constant Kernel:</p><p>$K_C(x_i, x_j) = C$</p></li><li><p>RBF Kernel:</p><p>$K_{RBF}(x_i, x_j) = e^{-\frac{|| x_i - x_j ||^2}{2 \sigma^2}}$</p></li><li><p>Periodic Kernel</p><p>Suitable for periodic relation</p><p>$K_{P}(x_i, x_j) = e^{-\frac{2 \sin^2 (\frac{d}{2})}{\ell^2}}$</p></li><li><p>Polynomial Kernel</p><p>$K_{Poly}(x_i, x_j) = ( x_i^{\top}x_j+ c)^d$</p></li><li><p>Neural Network Kernel</p><p>Model the neural network as GP, aka neural network Gaussian Process(NNGP). Intuitively, the kernel of NNGP compute the distance between the output vectors of 2 input data points.</p><p>We define the following functions as neural networks with fully-conntected layers:</p><p>$$z_{i}^{1}(x) = b_i^{1} + \sum_{j=1}^{N_1} \ W_{ij}^{1}x_j^1(x), \ \ x_{j}^{1}(x) = \phi(b_i^{0} + \sum_{k=1}^{d_{in}} \ W_{ik}^{0}x_k(x))$$</p><p>where $b_i^{1}$ is the $i$th-bias of the second layer(the same as first hidden layer), $W_{ij}^{1}$ is the $i$th-weights of the first layer(the same as input layer) , function $\phi$ is the activation function, and $x$ is the input data of the neural network. As a result,</p><p>Thus, the kernel of $l$-th layer is</p><p>$$K_{NN}^l(x, x') = \sigma_b^2 + \sigma_w^2 E_{z_i^{l-1} \sim GP(0, K^{l-1})}[\phi(z_i^{l-1}(x)) \phi(z_i^{l-1}(x'))]$$</p><p>For more detail, please refer to <a href=https://www.brown.edu/research/projects/crunch/sites/brown.edu.research.projects.crunch/files/uploads/Pang-NNGP-Crunch-Seminar.pdf>this slide</a> and the paper <a href=https://arxiv.org/abs/1711.00165>Deep Neural Networks as Gaussian Processes</a>.</p></li></ul><p>For more detail, please refer to <a href=https://distill.pub/2019/visual-exploration-gaussian-processes/>A Visual Exploration of Gaussian Processes</a>. You can play with interactive widgets on the website.</p><h2 id=inference>Inference<a hidden class=anchor aria-hidden=true href=#inference>#</a></h2><p>Given a training dataset with noise-free function values $f$ at inputs $X$, a GP prior can be converted into a GP posterior $p(f^{\ast}|X^{\ast},X,f)$ which can then be used to make predictions $f^{\ast}$ at new inputs $X^{\ast}$ By definition of a GP, the joint distribution of observed values $f$ and predictions $f^{\ast}$ is again a Gaussian which can be partitioned into</p><p>$$
\begin{pmatrix}
f\newline
f^{\ast}
\end{pmatrix}
\sim \mathcal{N}
\begin{pmatrix}
0,
\begin{pmatrix}
K & K^{\ast}\newline
K^{\ast \top} & K^{\ast \ast}
\end{pmatrix}
\end{pmatrix}$$</p><p>where $K^{\ast} = \kappa(X,X^{\ast})$ and $K^{\ast \ast} = \kappa(X^{\ast},X^{\ast})$. With $N$ training data and $N^{\ast}$ new input data $K$ is a $N√óN$ matrix , $K^{\ast}$ a $N√óN^{\ast}$ matrix and $K^{\ast \ast}$ a $N^{\ast}√óN^{\ast}$ matrix.</p><p>We&rsquo;ve known conditional distribution rules.</p><p>As a result, the predictive Gaussian Distribution is</p><p>$$p(f^{\ast} | X^{\ast},X,f) = \mathcal{N}(f^{\ast} | \mu^{\ast}, \Sigma^{\ast})$$</p><p>$$\mu^{\ast} = K^{\ast \top} K^{-1} f$$</p><p>$$\Sigma^{\ast} = K^{\ast \ast} - K^{\ast \top} K^{-1} K^{\ast}$$</p><p>However, the above equations don&rsquo;t consider the effect of noise. Suppose we need to evalutate a noisy model $y=f+\epsilon$ where $\epsilon \sim \mathcal{N}(0, \sigma_y^2 I)$ is the noise. The noise follows normal distribution and has a covariance matrix $\sigma_y^2 I$. Thus, the predictive distribution is</p><p>$$p(f^{\ast} | X^{\ast},X,y) = \mathcal{N}(f^{\ast} | \mu^{\ast}, \Sigma^{\ast})$$</p><p>$$\mu^{\ast} = K^{\ast \top} K_{y}^{-1} y$$</p><p>$$\Sigma^{\ast} = K^{\ast \ast} - K^{\ast \top} K_{y}^{-1} K^{\ast}$$</p><p>where $K_{y}^{-1} = K + \sigma_y^2 I$(linearilty of Gaussian distribution). Finally, we also want to replace the noise-free prediction $f^{\ast}$ with noisy prediction $y^{\ast}$. We can derive</p><p>$$p(y^{\ast} | X^{\ast},X,y) = \mathcal{N}(y^{\ast} | \mu^{\ast}, \Sigma^{\ast} + \sigma_y^2 I)$$</p><p>Finally, we get the probability of noisy prediction $y^{\ast}$ which conditions on noisy training dataset $X,y$ and test dataset $X^{\ast}$.</p><hr><h1 id=bayesian-optimization>Bayesian Optimization<a hidden class=anchor aria-hidden=true href=#bayesian-optimization>#</a></h1><p>In many machine learning or optimization problem, we need to optimize an unkown object function $f$. One of the solutions to optimize function $f$ is <strong>Bayesian Optimization</strong>. Bayesian Optimization assume the object function $f$ follows a distribution or prior model. This prior model is called <strong>surrogate model</strong>. We sample from the object function $f$ and approximate the function $f$ with surrogate model. The extra information like uncertainty provided from surrogate model contribute to the sample-efficiency of Bayesian optimization. In the mean time, we also use the <strong>acquisition function</strong> to choose the next sampling point.</p><h2 id=definition-1>Definition<a hidden class=anchor aria-hidden=true href=#definition-1>#</a></h2><p>Formaly, suppose we have a block-box function $f : X \to R$ that we with to minimize on some domain $x \subseteq X$ . That is, the Bayesian optimization wish to find</p><p>$$\begin{equation} x^{\ast} = \mathop{\arg\min}_{x \in X} \ \ f(x) \end{equation}$$</p><p>If we use Gaussian Process as prior(Surrogate Model), we can get</p><p>$$p(f) = GP(f; \mu, K)$$</p><p>Given observations $D = (x,f)$, we can condition our distribution on $D$ as usual</p><p>$$p(f | D) = GP(f; \mu_{f|D}, K_{f|D})$$</p><h2 id=surrogate-model>Surrogate Model<a hidden class=anchor aria-hidden=true href=#surrogate-model>#</a></h2><p>A popular model is Gaussian Process. Gaussian process defines a prior over functions and provides a flexiable, powerful and, smooth model which is especially suitable for dynamic models.</p><h2 id=algorithm>Algorithm<a hidden class=anchor aria-hidden=true href=#algorithm>#</a></h2><p>The Bayesian optimization procedure is as follows.</p><hr><p>For index $t=1,2,‚Ä¶$ and an acquisition function $a(x|D)$</p><p>repeat:</p><ul><li>Find the next sampling point $x_t$ by optimizing the acquisition function over the surrogate model:<h3 id=x_t--mathopargmax_x-in-x--axd_1t1><code>$x_t = \mathop{\arg\max}_{x \in X} \ a(x|D_{1:t‚àí1})$</code><a hidden class=anchor aria-hidden=true href=#x_t--mathopargmax_x-in-x--axd_1t1>#</a></h3><p>Or</p><h3 id=x_t--mathopargmin_x-in-x--axd_1t1><code>$x_t = \mathop{\arg\min}_{x \in X} \ a(x|D_{1:t‚àí1})$</code><a hidden class=anchor aria-hidden=true href=#x_t--mathopargmin_x-in-x--axd_1t1>#</a></h3><p>Depends on the definition of acquisition function $a(x|D_{1:t‚àí1})$</p></li><li>Obtain a possibly noisy sample $y_t=f(x_t)+\epsilon_t$ from the objective function $f$.</li><li>Add the sample to previous samples $D_{1:t}=D_{1:t‚àí1},(x_t,y_t)$ and update the surrogate model.</li></ul><hr><h2 id=probability-improvementpi-method>Probability improvement(PI) Method<a hidden class=anchor aria-hidden=true href=#probability-improvementpi-method>#</a></h2><p>A naive idea is always evaluating the points with lowest value and then we can obtain a better result in every iteration. The PI method do the same thing exactly. However, the Gaussian Process gives a distribution of $f(x)$ on point $x$. As a result, in practice, we give an threshold $f'$, integrate the probability of $x &lt; f'$ and, pick the point with highest probability. That is, <strong>PI always choose the point having largest probability of $x &lt; f'$</strong>.</p><p>Formaly, we can define an utility function $u(x)$</p><p>$$u(x) = \begin{cases}
0, \ \ f(x) > f'\newline
1, \ \ f(x) \leq f'
\end{cases}$$</p><p>Then, integrate the probability of $f(x) \leq f'$</p><p>$$
a_{PI}(x|D) = E[u(x) | x, D] = \int_{-\infty}^{f'} \mathcal{N}(f; \mu(x), \kappa(x, x)) \ df
=\phi(f'; \mu(x), \kappa(x, x))
$$</p><p>Finally, we choose next evaluating point $x_t$ with highest probability $a_{PI}(x|D_{1:t‚àí1})$</p><h3 id=beginequation-x_t--mathopargmax_x-in-x---a_pixd_1t1-endequation><code>$\begin{equation} x_t = \mathop{\arg\max}_{x \in X} \ \ a_{PI}(x|D_{1:t‚àí1}) \end{equation}$</code><a hidden class=anchor aria-hidden=true href=#beginequation-x_t--mathopargmax_x-in-x---a_pixd_1t1-endequation>#</a></h3><h2 id=expected-improvementei-method>Expected improvement(EI) Method<a hidden class=anchor aria-hidden=true href=#expected-improvementei-method>#</a></h2><p>PI algorithm is easy to understand. However, <strong>PI might get stuck in local optimal and underexplore globally</strong>. A better way is that we evaluates $f$ at the point that, in expectation, improves upon $f'$ the most. That is the idea of EI algorithm.</p><p>Formaly, we suppose that $f'$ is the minimal value of $f$ observed so far. We can define an utility function as following:</p><p>$$u(x) = \mathop{\max} (0, f' ‚àí f(x))$$</p><p>The ultility function can be regarded as the advanrage $f' - f(x)$ versus the current optimal $f'$. Then, we can derive the expectation via integration</p><p>$$
a_{EI}(x|D) = E[u(x) | x, D] = \int_{-\infty}^{f'} (f' - f) \mathcal{N}(f; \mu(x), \kappa(x, x)) \ df
$$</p><p>$$
=(f' - \mu(x))\phi(f'; \mu(x), \kappa(x, x)) + \kappa(x, x) \mathcal{N}(f'; \mu(x), \kappa(x, x))
$$</p><p>We always choose the next evaluating point $x_t$ which has highest $a_{EI}(x|D_{1:t‚àí1})$, thus</p><h3 id=beginequation-x_t--mathopargmax_x-in-x---a_eixd_1t1-endequation><code>$\begin{equation} x_t = \mathop{\arg\max}_{x \in X} \ \ a_{EI}(x|D_{1:t‚àí1}) \end{equation}$</code><a hidden class=anchor aria-hidden=true href=#beginequation-x_t--mathopargmax_x-in-x---a_eixd_1t1-endequation>#</a></h3><p>Intuitively, the term $(f' - \mu(x))\phi(f'; \mu(x), \kappa(x, x))$ can be seen as exploitation(it encourage to evaluate the point with higher advantage, lower $\mu(x)$), since it means how much advantage does point $x$ has. The term $\kappa(x, x) \mathcal{N}(f'; \mu(x), \kappa(x, x))$ represents how much uncertainty does point $x$ has, so it can be viewed as exploration(it encourage to evaluate the point with higher uncertainty, higher $\kappa(x, x)$). <strong>EI algorithm can trade off the exploration and exploitation automatically</strong> and also the most popular algorithm of Bayesian Optimization.</p><h2 id=bayesian-upper-confident-boundbayesian-ucb-aka-gp-ucb-method>Bayesian Upper Confident Bound(Bayesian UCB, aka GP-UCB) Method<a hidden class=anchor aria-hidden=true href=#bayesian-upper-confident-boundbayesian-ucb-aka-gp-ucb-method>#</a></h2><p>Before diving to Bayesian UCB method, please understand the multi-armed bandit problem and UCB first.</p><p>Bayesian UCB inherents UCB. They both give a relation between upper bound and probability confidence. The different thing is UCB finds the relation with Hoeffding&rsquo;s Inequality while Bayesian UCB find the relation with Gaussian distribution itself.</p><p>For example, it is common that we know if we sample values from Gaussian distribution, 95% of them are between the mean plus 2 standard deviation and mean subtract 2 standard deviation.</p><p><img src=/blog/img/gp/gaussian_dist_conf.png alt></p><p>Formally, we define the acquisition function as following</p><p>$$
a_{UCB}(x|D; \beta) = \mu(x) - \beta \sigma(x)
$$</p><p>where $\beta > 0$ is a tradeoff parameter and $\sigma(x) = \sqrt{\kappa(x, x)}$ is the marginal standard deviation of $f(x)$.</p><p>According the acquisition function, we always choose the next best evaluating point $x_t$</p><h3 id=beginequation-x_t--mathopargmin_x-in-x---a_ucbxd_1t1-beta-endequation><code>$\begin{equation} x_t = \mathop{\arg\min}_{x \in X} \ \ a_{UCB}(x|D_{1:t‚àí1}; \beta) \end{equation}$</code><a hidden class=anchor aria-hidden=true href=#beginequation-x_t--mathopargmin_x-in-x---a_ucbxd_1t1-beta-endequation>#</a></h3><p>Again, the GP-UCB acquisition function contains explicit exploitation ($\mu(x)$) and exploration ($\sigma(x)$) terms. Nonetheless, strong theoretical results are known for GP-UCB, namely, that under
certain conditions, the iterative application of this acquisition function will converge to the true
global minimum of $f$.</p><h2 id=entropy-search>Entropy Search<a hidden class=anchor aria-hidden=true href=#entropy-search>#</a></h2><p>Since we&rsquo;ve known the goal of the optimization problem is</p><p>$$\begin{equation} x^{\ast} = \mathop{\arg\min}_{x \in X} \ \ f(x) \end{equation}$$</p><p>where $x^{\ast}$ is the global optimal over the black-box function $f$. The entropy search aims to minimizing the entropy of $p(x^{\ast} | D)$. That is, minimize the uncerntainty of $x^{\ast}$ over the known data set $D$. We can define an utility function as following</p><p>$$u(x) = H[x^{\ast} | D] - H[x^{\ast} | D, x, f(x)]$$</p><p>where $H$ represent the Shannon entropy of the corresponding data point. The $u(x)$ means <strong>how much uncertinty of $p(x^{\ast} | D)$ does the evaluation reduce after the data point $x$ is evaluated</strong>. In most of the time, the entropy(uncertainty) of $p(x^{\ast} | D)$ should decrease after we evaluate more data points, so $u(x)$ should be positive in general. Thus, the acquisition function should be</p><p>$$a_{ES}(x|D) = E[u(x) | x, D]$$</p><p>However, we know $u(x)$ cannot be computed directly since it doesn&rsquo;t have close form. There are a series of approximations trying to do it but I will ignore thme in this blog. Finally, we can choose the next evaluation point $x_t$ as following</p><h3 id=beginequation-x_t--mathopargmax_x-in-x---a_esxd_1t1-beta-endequation><code>$\begin{equation} x_t = \mathop{\arg\max}_{x \in X} \ \ a_{ES}(x|D_{1:t‚àí1}; \beta) \end{equation}$</code><a hidden class=anchor aria-hidden=true href=#beginequation-x_t--mathopargmax_x-in-x---a_esxd_1t1-beta-endequation>#</a></h3><h1 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h1><p>This article is mainly based on</p><p>Gaussian Process</p><ul><li><p><a href=http://krasserm.github.io/2018/03/19/gaussian-processes/#References>Gaussian processes by Martin Krasser</a></p><p>Provide Python code to inference data with GP.</p></li><li><p><a href="https://www.youtube.com/watch?v=vU6AiEYED9E&list=PLD0F06AA0D2E8FFBA&index=150">(ML 19.1) Gaussian processes - definition and first examples</a></p><p>Made by mathematicalmonk. Give an intuitive explaination of Gaussian processes.</p></li><li><p><a href="https://distill.pub/2019/visual-exploration-gaussian-processes/?fbclid=IwAR3XSg_gQ9KvIG9qPOXCWjGGEhl7b3qSZCLxXeee-uDbuQtktLCf-2lVeno#DimensionSwap">A Visual Exploration of Gaussian Processes</a></p><p>Provide a lot of interactive widgets to play around with Gausssian Process but fewer math.</p></li><li><p><a href="https://www.youtube.com/watch?v=OdCXdUzLfao">Gaussian Processes - Part 1</a></p><p>Another video providing a detailed explaination of Gaussian Process.</p></li><li><p><a href="https://www.youtube.com/watch?v=92-98SYOd">ML Tutorial: Gaussian Processes (Richard Turner)</a></p><p>Another video providing a detailed explaination of Gaussian Process.</p></li><li><p><a href="https://www.youtube.com/watch?v=4vGiHC35j9s&t=2406s">UBC CS - Machine learning - Introduction to Gaussian processes</a></p><p><a href="https://www.youtube.com/watch?v=MfHKW5z-OOA">UBC CS - Machine learning - Gaussian processes</a></p><p>Another video providing a detailed explaination of Gaussian Process.</p></li></ul><p>Conditional Gaussian Distribution</p><ul><li><a href="https://www.youtube.com/watch?v=G6_OdMXpiVY">(PP 6.9) Conditional distributions of a Gaussian</a></li><li><a href=https://stats.stackexchange.com/questions/30588/deriving-the-conditional-distributions-of-a-multivariate-normal-distribution>StackExchange - Deriving the conditional distributions of a multivariate normal distribution</a></li></ul><p>Bayesian Optimization</p><ul><li><a href=http://krasserm.github.io/2018/03/21/bayesian-optimization/>Bayesian optimization by Martin Krasser</a></li><li><a href="https://www.youtube.com/watch?v=C5nqEHpdyoE">UAI 2018 2. Bayesian Optimization</a></li><li><a href=https://www.cse.wustl.edu/~garnett/cse515t/spring_2015/files/lecture_notes/12.pdf>Washington University CSE515 - Bayesian Optimization</a></li></ul><p>Kalman Filter</p><ul><li><p><a href=http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/>Bzarg: How a Kalman filter works, in pictures</a></p><p>Intuitively explain Kalman Filter with picture & examples.</p></li><li><p><a href=https://zhuanlan.zhihu.com/p/39912633>ÂõæËØ¥Âç°Â∞îÊõºÊª§Ê≥¢Ôºå‰∏Ä‰ªΩÈÄö‰øóÊòìÊáÇÁöÑÊïôÁ®ã</a></p><p>Intuitively explain Kalman Filter with picture & examples. The article is translated from Bzarg: How a Kalman filter works.</p></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://frankccccc.github.io/blog/tags/gaussian-process/>gaussian process</a></li><li><a href=https://frankccccc.github.io/blog/tags/bayesian-optimization/>bayesian optimization</a></li><li><a href=https://frankccccc.github.io/blog/tags/machine-learning/>machine learning</a></li><li><a href=https://frankccccc.github.io/blog/tags/random-process/>random process</a></li><li><a href=https://frankccccc.github.io/blog/tags/numerical-optimization/>numerical optimization</a></li><li><a href=https://frankccccc.github.io/blog/tags/bayes/>bayes</a></li></ul><nav class=paginav><a class=prev href=https://frankccccc.github.io/blog/posts/toward_nngp_and_ntk/><span class=title>¬´ Prev Page</span><br><span>Part II - Toward NNGP and NTK</span></a>
<a class=next href=https://frankccccc.github.io/blog/posts/a_set_of_shannon_entropy/><span class=title>Next Page ¬ª</span><br><span>A Set of Shannon Entropy</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share A Very Brief Introduction to Gaussian Process and Bayesian Optimization on twitter" href="https://twitter.com/intent/tweet/?text=A%20Very%20Brief%20Introduction%20to%20Gaussian%20Process%20and%20Bayesian%20Optimization&url=https%3a%2f%2ffrankccccc.github.io%2fblog%2fposts%2fintro_gp_bayes_opt%2f&hashtags=gaussianprocess%2cbayesianoptimization%2cmachinelearning%2crandomprocess%2cnumericaloptimization%2cbayes"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share A Very Brief Introduction to Gaussian Process and Bayesian Optimization on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ffrankccccc.github.io%2fblog%2fposts%2fintro_gp_bayes_opt%2f&title=A%20Very%20Brief%20Introduction%20to%20Gaussian%20Process%20and%20Bayesian%20Optimization&summary=A%20Very%20Brief%20Introduction%20to%20Gaussian%20Process%20and%20Bayesian%20Optimization&source=https%3a%2f%2ffrankccccc.github.io%2fblog%2fposts%2fintro_gp_bayes_opt%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share A Very Brief Introduction to Gaussian Process and Bayesian Optimization on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ffrankccccc.github.io%2fblog%2fposts%2fintro_gp_bayes_opt%2f&title=A%20Very%20Brief%20Introduction%20to%20Gaussian%20Process%20and%20Bayesian%20Optimization"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share A Very Brief Introduction to Gaussian Process and Bayesian Optimization on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ffrankccccc.github.io%2fblog%2fposts%2fintro_gp_bayes_opt%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share A Very Brief Introduction to Gaussian Process and Bayesian Optimization on whatsapp" href="https://api.whatsapp.com/send?text=A%20Very%20Brief%20Introduction%20to%20Gaussian%20Process%20and%20Bayesian%20Optimization%20-%20https%3a%2f%2ffrankccccc.github.io%2fblog%2fposts%2fintro_gp_bayes_opt%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share A Very Brief Introduction to Gaussian Process and Bayesian Optimization on telegram" href="https://telegram.me/share/url?text=A%20Very%20Brief%20Introduction%20to%20Gaussian%20Process%20and%20Bayesian%20Optimization&url=https%3a%2f%2ffrankccccc.github.io%2fblog%2fposts%2fintro_gp_bayes_opt%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><div style=padding-top:2.5rem;padding-bottom:2.5rem;text-align:left><h1 style=padding-bottom:.5rem>COMMENTS</h1><h5>Your comments will encouage me to share more~~</h5></div><div id=utter-container></div><script src=https://utteranc.es/client.js repo=frankccccc/blog issue-term=title theme=photon-dark crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2021 <a href=https://frankccccc.github.io/blog/>Golden Hat</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script defer src=/blog/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><script>window.onload=function(){localStorage.getItem("menu-scroll-position")&&(document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position"))},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})});var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft)}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>