<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>information theory on Golden Hat</title><link>https://frankccccc.github.io/blog/tags/information-theory/</link><description>Recent content in information theory on Golden Hat</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 23 Feb 2021 12:39:16 +0800</lastBuildDate><atom:link href="https://frankccccc.github.io/blog/tags/information-theory/index.xml" rel="self" type="application/rss+xml"/><item><title>A Set of Shannon Entropy</title><link>https://frankccccc.github.io/blog/posts/a_set_of_shannon_entropy/</link><pubDate>Tue, 23 Feb 2021 01:03:19 +0800</pubDate><guid>https://frankccccc.github.io/blog/posts/a_set_of_shannon_entropy/</guid><description>Shannon Entropy For discrete random variable $X$ with events $\{ x_1, &amp;hellip;, x_n \}$ and probability mass function $P(X)$, we defien the Shannon Entropy $H(X)$ as
$$H(X) = E[-log_b \ P(X)] = - \sum_{i = 1}^{i = n} \ P(x_i) log_b \ P(x_i)$$
where $b$ is the base of the logarithm. The unit of Shannon entropy is bit for $b = 2$ while nat for $b = e$
The Perspective of Venn Diagram We can illustrate the relation between joint entropy, conditional entropy, and mutual entropy as the following figure</description></item><item><title>A Guide Of Variational Lower Bound</title><link>https://frankccccc.github.io/blog/posts/a_guide_of_variational_lower_bound/</link><pubDate>Tue, 23 Feb 2021 12:39:16 +0800</pubDate><guid>https://frankccccc.github.io/blog/posts/a_guide_of_variational_lower_bound/</guid><description>Problem Setup The Variational Lower Bound is also knowd as Evidence Lower Bound(ELBO) or VLB. It is quite useful that we can derive a lower bound of a model containing a hidden variable. Futhermore, we can even maximize the bound to maximize the log probability. We can assume that $X$ are observations (data) and $Z$ are hidden/latent variables which is unobservable. In general, we can also imagine $Z$ as a parameter and the relationship between $Z$ and $X$ are represented as the following</description></item></channel></rss>