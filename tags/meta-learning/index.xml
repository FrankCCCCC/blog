<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>meta learning on Golden Hat</title><link>https://frankccccc.github.io/blog/tags/meta-learning/</link><description>Recent content in meta learning on Golden Hat</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 15 Mar 2021 23:48:35 +0800</lastBuildDate><atom:link href="https://frankccccc.github.io/blog/tags/meta-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>A Paper Review: Learning to Adapt</title><link>https://frankccccc.github.io/blog/posts/a_paper_review_learning_to_adapt/</link><pubDate>Mon, 15 Mar 2021 23:48:35 +0800</pubDate><guid>https://frankccccc.github.io/blog/posts/a_paper_review_learning_to_adapt/</guid><description>Introduciton Propose an efficient method for online adaptation. The algorithm efficiently trains a global model that is capable of using its recent experiences to quickly adapt, achieving fast online adaptation in dynamic environments.
They evaluate 2 version of approaches on stochastic continuous control tasks:
(1) Recurrence-Based Adaptive Learner (ReBAL)
(2) Gradient-Based Adaptive Learner (GrBAL)
Objective Setting-Up To adapt the dynamic environment, we require a learned model $p_{\theta}^$ to adapt, using an update rule $u_{\psi}^$ after seeing M data points from some new &amp;ldquo;task&amp;rdquo;.</description></item></channel></rss>