<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Golden Hat</title><link>https://frankccccc.github.io/blog/</link><description>Recent content on Golden Hat</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 23 Feb 2021 12:39:16 +0800</lastBuildDate><atom:link href="https://frankccccc.github.io/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>A Guide Of Variational Lower Bound</title><link>https://frankccccc.github.io/blog/posts/a_guide_of_variational_lower_bound/</link><pubDate>Tue, 23 Feb 2021 12:39:16 +0800</pubDate><guid>https://frankccccc.github.io/blog/posts/a_guide_of_variational_lower_bound/</guid><description>Problem Setup It is also knowd as Evidence Lower Bound(ELBO) or VLB. We can assume that $X$ are observations (data) and $Z$ are hidden/latent variables. In general, we can also imagine $Z$ as a parameter and the relationship between $Z$ and $X$ are represented as the following
In the mean time, by the definition of Bayes' Theorem and conditional probability, we can get
$$p(Z | X) = \frac{p(X | Z) p(Z)}{p(X)} = \frac{p(X | Z) p(Z)}{\int_{Z} p(X, Z)}$$</description></item><item><title>A Set of Shannon Entropy</title><link>https://frankccccc.github.io/blog/posts/a_set_of_shannon_entropy/</link><pubDate>Tue, 23 Feb 2021 01:03:19 +0800</pubDate><guid>https://frankccccc.github.io/blog/posts/a_set_of_shannon_entropy/</guid><description>Shannon Entropy For discrete random variable $X$ with events $\{ x_1, &amp;hellip;, x_n \}$ and probability mass function $P(X)$, we defien the Shannon Entropy $H(X)$ as
$$H(X) = \mathbb{E}[-log_b \ P(X)] = - \Sigma_{i = 1}^{i = n} \ P(x_i) log_b \ P(x_i)$$
where $b$ is the base of the logarithm. The unit of Shannon entropy is bit for $b = 2$ while nat for $b = e$
The Perspective of Venn Diagram We can illustrate the relation between joint entropy, conditional entropy, and mutual entropy as the following figure</description></item><item><title>Toward NNGP and NTK</title><link>https://frankccccc.github.io/blog/posts/toward_nngp_and_ntk/</link><pubDate>Fri, 19 Feb 2021 20:46:29 +0800</pubDate><guid>https://frankccccc.github.io/blog/posts/toward_nngp_and_ntk/</guid><description>Neural Network Gaussian Process(NNGP) Neural Tangent Kernel(NTK)
&amp;ldquo;In short, NTK represent the changes of the weights before and after the gradient descent update&amp;rdquo; Let&amp;rsquo;s start the journey of revealing the black-box neural networks.
Setup a Neural Network First of all, we need to define a simple neural network with 2 hidden layers
$$ y(x, w)$$
where $y$ is the neural network with weights $w \in \mathbb{R}^m$ and, $\{ x, \bar{y} \}$ is the dataset which is a set of the input data and the output data with $N$ data points.</description></item><item><title>An Insight Into MLE, MAP, and Bayesian Estimation</title><link>https://frankccccc.github.io/blog/posts/mle_map_bayes/</link><pubDate>Fri, 19 Feb 2021 11:15:15 +0800</pubDate><guid>https://frankccccc.github.io/blog/posts/mle_map_bayes/</guid><description>The main different between 3 kinds of estimation is What do we assume for the prior? The Maximum Likelihood Estimation(MLE) doesn&amp;rsquo;t use any prior but only maiximize the probability according to the samples. On the other hand, MAP and Bayesian both use priors to estimate the probability. The Maximum A Posteriori(MAP) only use the probability of single event while Bayesian Estimation see a distribution as the prior.
To be continue&amp;hellip;</description></item><item><title>Part I - From Alphago to Muzero</title><link>https://frankccccc.github.io/blog/posts/alphago/</link><pubDate>Fri, 19 Feb 2021 01:14:40 +0800</pubDate><guid>https://frankccccc.github.io/blog/posts/alphago/</guid><description/></item><item><title>A Glimpse of Distributional RL</title><link>https://frankccccc.github.io/blog/posts/distributional_rl/</link><pubDate>Tue, 16 Feb 2021 20:36:18 +0800</pubDate><guid>https://frankccccc.github.io/blog/posts/distributional_rl/</guid><description/></item><item><title>An Introduction to Multi-Armed Bandit Problem and Solutions</title><link>https://frankccccc.github.io/blog/posts/bandit/</link><pubDate>Tue, 16 Feb 2021 20:11:41 +0800</pubDate><guid>https://frankccccc.github.io/blog/posts/bandit/</guid><description>Multi-Armed Bandit Problem Imagine you are in a casionoand face multiple slot machines. Each machine is configured with an unknown probability of how likely you would get a reward at one play. The question is What&amp;rsquo;s the strategy to get the highest long-term reward?
An illustration of multi-armed bandit problem, refer to Lil&amp;rsquo;Log The Multi-Armed Bandit Problem and Its Solutions
Definition Upper Confidence Bounds(UCB) The UCB algorithm give a realtion between upper bound and probability confidence.</description></item><item><title>A Very Brief Introduction to Gaussian Process and Bayesian Optimization</title><link>https://frankccccc.github.io/blog/posts/intro_gp_bayes_opt/</link><pubDate>Tue, 16 Feb 2021 17:28:58 +0800</pubDate><guid>https://frankccccc.github.io/blog/posts/intro_gp_bayes_opt/</guid><description>Gaussian Process Big Picture and Background Intuitively, Gaussian distribution define the state space, while Gaussian Process define the function space
Before we introduce Gaussian process, we should understand Gaussian distriution at first. For a RV(random variable) $X$ that follow Gaussian Distribution $\mathcal{N}(0, 1)$ should be following image:
The P.D.F should be
$$x \sim \mathcal{N}(\mu, \sigma) = \frac{1}{\sigma \sqrt{2 \pi}} e^{- \frac{1}{2} (\frac{- \mu}{\sigma})^2}$$
As for Multivariate Gaussian Distribution, given 2 RV $x$, $y$ both 2 RV follow Gaussian Distribution $\mathcal{N}(0, 1)$ we can illustrate it as</description></item><item><title>部落格搬家記</title><link>https://frankccccc.github.io/blog/posts/move_blog/</link><pubDate>Tue, 16 Feb 2021 17:28:58 +0800</pubDate><guid>https://frankccccc.github.io/blog/posts/move_blog/</guid><description>因為寫DL筆記時會用到大量數學符號，就索性把原先在Github上的DL_DB_Quick_Notes搬過來了，配合LATEX寫筆記順手很多，原先的Repo應該只會剩下收集Paper用。而最近生活上有些轉折，也許也會順便放些隨筆雜記，但就依心情而定。
目前用的主題是PaperMod，整體設計算令人滿意，只不過在Deploy Hugo遇到蠻多麻煩，這邊簡單記錄一下
設定Github Page Action 參考PaperMod ExampleSite的gh-pages.yml設定，自己再作一些修改，大致如下
name: Build GH-Pages on: push: paths-ignore: - 'images/**' - 'LICENSE' - 'README.md' branches: - master workflow_dispatch: # manual run jobs: deploy: runs-on: ubuntu-latest steps: - name: Git checkout uses: actions/checkout@v2 with: ref: master - name: Get Theme run: git submodule update --init --recursive - name: Update theme to Latest commit run: git submodule update --remote --merge - name: Setup hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: 'latest' - name: Build run: hugo --buildDrafts --gc --verbose --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.</description></item><item><title>Search</title><link>https://frankccccc.github.io/blog/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://frankccccc.github.io/blog/search/</guid><description>search</description></item></channel></rss>